# Paperless-NGX connection
# Set to your Paperless-NGX URL and API token
PAPERLESS_URL=http://your-paperless-host:8000
PAPERLESS_TOKEN=replace_with_your_token

# Ollama (local LLM runtime)
OLLAMA_BASE_URL=http://localhost:11434
# Recommended model for M-series: qwen2.5:3b
OLLAMA_MODEL=qwen2.5:3b
OLLAMA_EMBEDDING_MODEL=bge-m3

# Vector DB
VECTOR_DB_PATH=./data/vector_db
COLLECTION_NAME=paperless_fast

# Chunking (tuned for BGE-M3 / larger context)
CHUNK_SIZE=512
CHUNK_OVERLAP=50
MAX_CHUNK_SIZE=1000

# Retrieval / RAG
TOP_K=3
RERANK_ENABLED=false

# LLM generation defaults
LLM_MAX_TOKENS=200
LLM_NUM_CTX=2048
LLM_TEMPERATURE=0.0

# Performance tuning
MAX_CONCURRENT_QUERIES=4
ENABLE_STREAMING=true

# Legacy / advanced (optional)
# BGE_M3_DENSE_WEIGHT=0.5
# BGE_M3_SPARSE_WEIGHT=0.3
# BGE_M3_COLBERT_WEIGHT=0.2
# BGE_M3_USE_FP16=true
# BGE_M3_MAX_LENGTH=8192
